"""
æ–‡æ¡£ç»´æŠ¤å·¥å…· - ç”¨äºæ£€æŸ¥å’ŒåŒæ­¥å¤šè¯­è¨€æ–‡æ¡£

ç”¨æ³•ç¤ºä¾‹:
python doc_maintainer.py --path ./docs --langs en,zh,es --primary en
"""

from metagpt.actions import Action
from metagpt.roles import Role
from pathlib import Path
from typing import ClassVar, Dict, List
import re
import json
import argparse
import asyncio
import logging
from datetime import datetime
from colorama import Fore, Style, init

# åˆå§‹åŒ–coloramaä»¥æ”¯æŒWindowsé¢œè‰²è¾“å‡º
init()

# è®¾ç½®æ—¥å¿—æ ¼å¼
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S',
    handlers=[]  # Remove default handlers since we'll add custom ones
)
logger = logging.getLogger('DocMaintainer')


# æ·»åŠ æµå¤„ç†å™¨ä»¥å°†æ—¥å¿—è¾“å‡ºåˆ°ç»ˆç«¯ï¼ˆä¿ç•™é¢œè‰²ï¼‰
stream_handler = logging.StreamHandler()
stream_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
stream_handler.setFormatter(stream_formatter)
logger.addHandler(stream_handler)


# åˆ›å»ºä¸€ä¸ªè¿‡æ»¤å™¨æ¥ç§»é™¤ANSIé¢œè‰²ä»£ç 
class ColorStripper(logging.Filter):
    def filter(self, record):
        if isinstance(record.msg, str):
            # ç§»é™¤ANSIé¢œè‰²ä»£ç 
            ansi_escape = re.compile(r'\x1B(?:[@-Z\\-_]|\[[0-?]*[ -/]*[@-~])')
            record.msg = ansi_escape.sub('', record.msg)
        return True

# æ·»åŠ æ–‡ä»¶å¤„ç†å™¨ä»¥å°†æ—¥å¿—å†™å…¥åˆ°æ–‡ä»¶ï¼ˆæ— é¢œè‰²ï¼‰
file_handler = logging.FileHandler('doc_maintainer.log')
file_formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
file_handler.setFormatter(file_formatter)
file_handler.addFilter(ColorStripper())  # æ·»åŠ é¢œè‰²è¿‡æ»¤å™¨
logger.addHandler(file_handler)

# è®¾ç½®æ—¥å¿—çº§åˆ«
logger.setLevel(logging.INFO)

# Actionç±»å®šä¹‰
class CheckDocStructureAction(Action):
    """æ£€æŸ¥æ–‡æ¡£ç›®å½•ç»“æ„å·®å¼‚""" 
    async def run(self, base_path: Path, lang_dirs: list):
        structure = {}
        for lang in lang_dirs:
            lang_path = base_path / lang
            if not lang_path.exists():
                logger.warning(f"{Fore.YELLOW}è¯­è¨€ç›®å½•ä¸å­˜åœ¨: {lang_path}{Style.RESET_ALL}")
                structure[lang] = set()
                continue
                
            files = [str(p.relative_to(lang_path)) for p in lang_path.rglob('*.md')]
            structure[lang] = set(files)
            logger.info(f"{Fore.GREEN}å·²æ‰«æ {lang} ç›®å½•: å‘ç° {len(files)} ä¸ªæ–‡æ¡£{Style.RESET_ALL}")
        return structure

class TranslationAction(Action):
    """æ‰§è¡Œæ–‡æ¡£ç¿»è¯‘çš„Action"""
    PROMPT_TEMPLATE: ClassVar[str] = """
    å°†ä»¥ä¸‹{source_lang}æ–‡æ¡£å‡†ç¡®ç¿»è¯‘æˆ{target_lang}ï¼Œä¿æŒä¸“ä¸šè¯­æ°”å’ŒæŠ€æœ¯å‡†ç¡®æ€§ï¼Œä¿ç•™åŸæ–‡çš„æ‰€æœ‰æ ¼å¼ã€æ ‡è®°å’Œç»“æ„ã€‚
    å¯¹äºè¾ƒé•¿å†…å®¹ï¼Œè¯·ç¡®ä¿å®Œæ•´ç¿»è¯‘æ¯ä¸€æ®µè½ï¼Œä¸è¦é—æ¼æˆ–ç®€åŒ–ä»»ä½•éƒ¨åˆ†ã€‚
    ç›´æ¥è¾“å‡ºç¿»è¯‘ç»“æœï¼Œæ— éœ€é¢å¤–è¯´æ˜ï¼š
    
    {content}
    """
    
    IMPROVEMENT_PROMPT_TEMPLATE: ClassVar[str] = """
    è¯·æ”¹è¿›ä»¥ä¸‹{target_lang}ç¿»è¯‘æ–‡æ¡£ï¼Œä½¿å…¶æ›´å‡†ç¡®åœ°åæ˜ {source_lang}åŸæ–‡å†…å®¹ã€‚
    
    åŸæ–‡({source_lang}):
    {source_content}
    
    ç°æœ‰ç¿»è¯‘({target_lang}):
    {target_content}
    
    è¦æ±‚:
    1. ä¿ç•™ç°æœ‰ç¿»è¯‘ä¸­æ­£ç¡®ä¸”åˆé€‚çš„éƒ¨åˆ†
    2. ä¿®æ­£ä¸å‡†ç¡®æˆ–ä¸æ°å½“çš„ç¿»è¯‘éƒ¨åˆ†
    3. è¡¥å……åŸæ–‡ä¸­æœ‰ä½†ç¿»è¯‘ä¸­ç¼ºå¤±çš„å†…å®¹
    4. ä¿æŒåŸæ–‡çš„æ‰€æœ‰æ ¼å¼ã€æ ‡è®°å’Œç»“æ„
    
    è¯·è¾“å‡ºå®Œæ•´çš„æ”¹è¿›åæ–‡æ¡£ï¼Œè€Œä¸åªæ˜¯æ›´æ”¹çš„éƒ¨åˆ†ï¼š
    """
    
    def _remove_tags(self, content: str) -> str:
        """ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼å»é™¤ç‰¹å®šæ ‡è®°"""
        return re.sub(r'<think>[^<]*?</think>\n\n', '', content, flags=re.DOTALL)
    
    async def run(self, content: str, source_lang: str, target_lang: str, existing_translation: str = None):
        """æ‰§è¡Œç¿»è¯‘ï¼Œå¦‚æœ‰ç°æœ‰ç¿»è¯‘åˆ™è¿›è¡Œæ”¹è¿›è€Œéé‡æ–°ç¿»è¯‘"""
        logger.info(f"{Fore.BLUE}ğŸŒ æ‰§è¡Œ{'ç¿»è¯‘æ”¹è¿›' if existing_translation else 'æ–°ç¿»è¯‘'}: {source_lang} â†’ {target_lang}{Style.RESET_ALL}")
        
        if existing_translation:
            # å¦‚æœæœ‰ç°æœ‰ç¿»è¯‘ï¼Œä½¿ç”¨æ”¹è¿›æ¨¡å¼
            return await self._aask(
                self.IMPROVEMENT_PROMPT_TEMPLATE.format(
                    source_content=content,
                    source_lang=source_lang,
                    target_content=existing_translation,
                    target_lang=target_lang
                )
            )
        else:
            # æ²¡æœ‰ç°æœ‰ç¿»è¯‘ï¼Œè¿›è¡Œå…¨æ–°ç¿»è¯‘
            return await self._aask(
                self.PROMPT_TEMPLATE.format(
                    content=content,
                    source_lang=source_lang,
                    target_lang=target_lang
                )
            )

class GenerateDocAction(Action):
    """ç”Ÿæˆç¼ºå¤±æ–‡æ¡£çš„Action"""
    def _remove_tags(self, content: str) -> str:
        """ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼å»é™¤ç‰¹å®šæ ‡è®°"""
        return re.sub(r'<think>[^<]*?</think>\n\n', '', content, flags=re.DOTALL)

    async def run(self, missing_files: dict, base_path: Path, structure: dict, primary_lang: str, dry_run: bool = False):
        """åŸºäºç°æœ‰è¯­è¨€ç‰ˆæœ¬ç”Ÿæˆç¼ºå¤±çš„æ–‡æ¡£
        
        Args:
            missing_files: ç¼ºå¤±æ–‡ä»¶çš„å­—å…¸ {è¯­è¨€: [æ–‡ä»¶è·¯å¾„]}
            base_path: æ–‡æ¡£æ ¹ç›®å½•
            structure: æ–‡æ¡£ç»“æ„ä¿¡æ¯
            primary_lang: ä¸»è¦è¯­è¨€
            dry_run: å¦‚æœä¸ºTrueï¼Œä»…æ‰“å°æ“ä½œä½†ä¸æ‰§è¡Œ
            
        Returns:
            dict: æ“ä½œç»Ÿè®¡ä¿¡æ¯
        """
        stats = {"planned": 0, "created": 0, "skipped": 0}
        
        for target_lang, files in missing_files.items():
            for file in files:
                # ä¼˜å…ˆä½¿ç”¨ä¸»è¦è¯­è¨€ä½œä¸ºæºè¯­è¨€
                source_lang = None
                source_content = None
                
                # é¦–å…ˆå°è¯•ä½¿ç”¨ä¸»è¦è¯­è¨€
                if primary_lang in structure and file in structure[primary_lang]:
                    source_lang = primary_lang
                    source_path = base_path / primary_lang / file
                    if source_path.exists():
                        source_content = source_path.read_text(encoding='utf-8')
                
                # å¦‚æœä¸»è¦è¯­è¨€æ²¡æœ‰è¯¥æ–‡ä»¶ï¼Œå°è¯•å…¶ä»–è¯­è¨€
                if not source_content:
                    for lang in structure:
                        if file in structure[lang] and lang != target_lang:
                            source_lang = lang
                            source_path = base_path / lang / file
                            if source_path.exists():
                                source_content = source_path.read_text(encoding='utf-8')
                                break
                
                if source_lang and source_content:
                    target_path = base_path / target_lang / file
                    stats["planned"] += 1
                    
                    # æ‰“å°æ“ä½œä¿¡æ¯
                    logger.info(f"{Fore.BLUE}éœ€è¦ç¿»è¯‘: {source_lang} â†’ {target_lang} : {file}{Style.RESET_ALL}")
                    
                    if dry_run:
                        logger.info(f"{Fore.YELLOW}[æ¨¡æ‹Ÿ] å°†åˆ›å»ºç¿»è¯‘: {target_path}{Style.RESET_ALL}")
                        continue
                    
                    # ç¿»è¯‘å†…å®¹
                    translated_content = await TranslationAction().run(
                        source_content, 
                        source_lang, 
                        target_lang
                    )

                    # å†™å…¥å‰æ·»åŠ è¿‡æ»¤
                    filtered_content = self._remove_tags(translated_content)
                    
                    # ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
                    target_path.parent.mkdir(parents=True, exist_ok=True)
                    target_path.write_text(filtered_content, encoding='utf-8')
                    
                    logger.info(f"{Fore.GREEN}âœ“ åˆ›å»ºç¿»è¯‘æ–‡ä»¶: {target_path}{Style.RESET_ALL}")
                    stats["created"] += 1
                else:
                    logger.warning(f"{Fore.YELLOW}æ— æ³•ç¿»è¯‘ {file} åˆ° {target_lang}: æœªæ‰¾åˆ°æºæ–‡ä»¶{Style.RESET_ALL}")
                    stats["skipped"] += 1
        
        return stats

class CompareDocumentAction(Action):
    """æ¯”è¾ƒæ–‡æ¡£å¹¶è¯†åˆ«å·®å¼‚"""
    
    DOCUMENT_COMPARISON_PROMPT: ClassVar[str] = """
    è¯·æ¯”è¾ƒä»¥ä¸‹ä¸¤ç§è¯­è¨€ç‰ˆæœ¬çš„æ–‡æ¡£ï¼Œåˆ¤æ–­æ˜¯å¦å­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼š
    
    ## æºæ–‡æ¡£ ({source_lang}):
    {source_content}
    
    ## ç›®æ ‡æ–‡æ¡£ ({target_lang}):
    {target_content}
    
    ## è¦æ±‚:
    1. æ£€æŸ¥ä¸¤ä¸ªæ–‡æ¡£ä¹‹é—´æ˜¯å¦å­˜åœ¨æœ‰æ„ä¹‰çš„å·®å¼‚
    2. ä¸€æ—¦å‘ç°æ˜æ˜¾å·®å¼‚ï¼Œç«‹å³åœæ­¢åˆ†æ
    
    ## è¿”å›æ ¼å¼:
    è¯·ç›´æ¥è¿”å›JSONæ ¼å¼çš„ç»“æœï¼Œä¸è¦åŒ…å«å…¶ä»–è§£é‡Šï¼š
    {{
        "has_differences": true/false
    }}
    """
    
    def _remove_tags(self, content: str) -> str:
        """ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼å»é™¤ç‰¹å®šæ ‡è®°"""
        return re.sub(r'<think>[^<]*?</think>\n\n', '', content, flags=re.DOTALL)
    
    async def run(self, source_path: Path, target_path: Path, source_lang: str, target_lang: str):
        """æ¯”è¾ƒä¸¤ä¸ªæ–‡æ¡£ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å·®å¼‚
        
        Returns:
            Dict: åŒ…å«å·®å¼‚ç»“æœçš„å­—å…¸
        """
        logger.debug(f"æ¯”è¾ƒæ–‡æ¡£: {source_path.name} ({source_lang} vs {target_lang})")
        source_content = source_path.read_text(encoding='utf-8')
        target_content = target_path.read_text(encoding='utf-8')
        
        # ä½¿ç”¨LLMè¿›è¡Œæ–‡æ¡£æ¯”è¾ƒ
        comparison_response = await self._aask(
            self.DOCUMENT_COMPARISON_PROMPT.format(
                source_lang=source_lang,
                source_content=source_content,
                target_lang=target_lang,
                target_content=target_content
            )
        )
        
        # å¤„ç†LLMè¿”å›çš„ç»“æœ
        try:
            # ç§»é™¤ç‰¹å®šæ ‡ç­¾
            cleaned_response = self._remove_tags(comparison_response)
            
            # å°è¯•è§£æJSON
            try:
                result = json.loads(cleaned_response)
            except json.JSONDecodeError:
                # å°è¯•æå–JSONéƒ¨åˆ†
                json_match = re.search(r'\{(?:[^{}]|(?:\{[^{}]*\}))*\}', cleaned_response)
                if json_match:
                    try:
                        result = json.loads(json_match.group(0))
                    except json.JSONDecodeError:
                        raise ValueError("æ— æ³•è§£ææå–çš„JSONå†…å®¹")
                else:
                    raise ValueError("å“åº”ä¸­æ‰¾ä¸åˆ°æœ‰æ•ˆçš„JSONæ ¼å¼")
            
            # ç¡®ä¿ç»“æœåŒ…å«å¿…éœ€çš„é”®
            if "has_differences" not in result:
                result["has_differences"] = False
                    
            return result
            
        except Exception as e:
            logger.error(f"{Fore.RED}è§£ææ¯”è¾ƒç»“æœå¤±è´¥: {e}{Style.RESET_ALL}")
            logger.debug(f"åŸå§‹å“åº”: {comparison_response[:200]}...")
            
            # è¿”å›é»˜è®¤ç»“æ„
            return {
                "has_differences": False,
                "error": str(e)
            }

class DocumentSynchronizationAction(Action):
    """æ–‡æ¡£åŒæ­¥ï¼Œæ ¹æ®æ¯”è¾ƒç»“æœæ”¹è¿›ç¿»è¯‘"""
    
    def _remove_tags(self, content: str) -> str:
        """ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼å»é™¤ç‰¹å®šæ ‡è®°"""
        return re.sub(r'<think>[^<]*?</think>\n\n', '', content, flags=re.DOTALL)
    
    async def run(self, comparison_result: Dict, source_path: Path, target_path: Path, 
                  source_lang: str, target_lang: str, dry_run: bool = False):
        """æ ¹æ®æ¯”è¾ƒç»“æœåŒæ­¥æ–‡æ¡£å†…å®¹
        
        Args:
            comparison_result: CompareDocumentActionè¿”å›çš„æ¯”è¾ƒç»“æœ
            source_path: æºæ–‡æ¡£è·¯å¾„
            target_path: ç›®æ ‡æ–‡æ¡£è·¯å¾„
            source_lang: æºè¯­è¨€
            target_lang: ç›®æ ‡è¯­è¨€
            dry_run: å¦‚æœä¸ºTrueï¼Œä»…æ‰“å°æ“ä½œä½†ä¸æ‰§è¡Œ
        
        Returns:
            bool: æ˜¯å¦è¿›è¡Œäº†æ›´æ”¹
        """
        # å¦‚æœä¸éœ€è¦æ”¹è¿›ï¼Œç›´æ¥è¿”å›
        if not comparison_result.get("has_differences", False):
            return False
            
        logger.info(f"{Fore.YELLOW}æ–‡æ¡£éœ€è¦æ”¹è¿›: {target_path.name} - å‘ç°å·®å¼‚{Style.RESET_ALL}")
        
        if dry_run:
            logger.info(f"{Fore.YELLOW}[æ¨¡æ‹Ÿ] å°†æ”¹è¿›æ–‡æ¡£: {target_path}{Style.RESET_ALL}")
            return True
            
        source_content = source_path.read_text(encoding='utf-8')
        
        # å¦‚æœç›®æ ‡æ–‡ä»¶å­˜åœ¨ï¼Œåˆ™è¯»å–ç°æœ‰ç¿»è¯‘ï¼Œå¦åˆ™ä¸ºNone
        existing_translation = None
        if target_path.exists():
            existing_translation = target_path.read_text(encoding='utf-8')
            
        # ç¿»è¯‘æˆ–æ”¹è¿›æ–‡æ¡£
        translation = await TranslationAction().run(
            source_content,
            source_lang,
            target_lang,
            existing_translation
        )
        
        # ç§»é™¤ç‰¹å®šæ ‡ç­¾
        cleaned_translation = self._remove_tags(translation)
        
        # å†™å…¥æ›´æ–°åçš„ç¿»è¯‘
        target_path.parent.mkdir(parents=True, exist_ok=True)
        target_path.write_text(cleaned_translation, encoding='utf-8')
        
        logger.info(f"{Fore.GREEN}âœ“ {'æ›´æ–°' if existing_translation else 'åˆ›å»º'}æ–‡ä»¶: {target_path}{Style.RESET_ALL}")
        return True


class DocMaintainer(Role):
    """æ–‡æ¡£ç»´æŠ¤ä¸»è§’è‰²"""
    def __init__(self, base_path: str = "docs", lang_dirs: List[str] = ["en", "zh"], 
                 primary_lang: str = "en", verbose: bool = False, dry_run: bool = False):
        """åˆå§‹åŒ–æ–‡æ¡£ç»´æŠ¤è§’è‰²
        
        Args:
            base_path: æ–‡æ¡£æ ¹ç›®å½•
            lang_dirs: è¯­è¨€ç›®å½•åˆ—è¡¨
            primary_lang: ä¸»è¦è¯­è¨€ï¼ˆä½œä¸ºç¿»è¯‘æºï¼‰
            verbose: æ˜¯å¦æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯
            dry_run: å¦‚æœä¸ºTrueï¼Œä¸å®é™…ä¿®æ”¹æ–‡ä»¶
        """
        super().__init__()
        self.base_path = Path(base_path)
        self.lang_dirs = lang_dirs
        self.primary_lang = primary_lang
        self.verbose = verbose
        self.dry_run = dry_run
        
        # è®¾ç½®æ—¥å¿—çº§åˆ«
        if verbose:
            logger.setLevel(logging.DEBUG)
        else:
            logger.setLevel(logging.INFO)
            
        self.set_actions([
            CheckDocStructureAction,
            TranslationAction, 
            GenerateDocAction,
            CompareDocumentAction,
            DocumentSynchronizationAction
        ])
        
        self.stats = {
            "missing_files": 0,
            "files_to_improve": 0,
            "files_created": 0,
            "files_improved": 0
        }
        
    def _find_missing(self, structure: dict):
        """å®ç°æŸ¥æ‰¾ç¼ºå¤±æ–‡ä»¶çš„é€»è¾‘"""
        all_files = set().union(*structure.values()) if structure.values() else set()
        missing = {}
        for lang in structure:
            missing_files = all_files - structure[lang]
            missing[lang] = missing_files
            if missing_files:
                self.stats["missing_files"] += len(missing_files)
                
        return missing
    
    async def check_and_generate_docs(self):
        """æ£€æŸ¥å¹¶ç”Ÿæˆç¼ºå¤±çš„æ–‡æ¡£"""
        logger.info(f"{Fore.CYAN}ğŸ” å¼€å§‹æ£€æŸ¥æ–‡æ¡£ç»“æ„: {self.base_path}{Style.RESET_ALL}")
        
        # 1. æ£€æŸ¥æ–‡æ¡£ç»“æ„
        structure = await CheckDocStructureAction().run(self.base_path, self.lang_dirs)
        
        # 2. è¯†åˆ«ç¼ºå¤±æ–‡ä»¶
        missing_files = self._find_missing(structure)
        
        # 3. ç»Ÿè®¡ç¼ºå¤±æ–‡ä»¶
        total_missing = sum(len(files) for files in missing_files.values())
        if total_missing > 0:
            logger.info(f"{Fore.YELLOW}å‘ç° {total_missing} ä¸ªç¼ºå¤±æ–‡ä»¶{Style.RESET_ALL}")
            for lang, files in missing_files.items():
                if files:
                    logger.info(f"  {Fore.YELLOW}{lang}: ç¼ºå°‘ {len(files)} ä¸ªæ–‡ä»¶{Style.RESET_ALL}")
                    if self.verbose:
                        for f in files:
                            logger.debug(f"    - {f}")
        else:
            logger.info(f"{Fore.GREEN}æœªå‘ç°ç¼ºå¤±æ–‡ä»¶{Style.RESET_ALL}")
        
        # 4. ç”Ÿæˆç¼ºå¤±æ–‡æ¡£
        if total_missing > 0:
            if self.dry_run:
                logger.info(f"{Fore.YELLOW}[æ¨¡æ‹Ÿæ¨¡å¼] å°†ç”Ÿæˆ {total_missing} ä¸ªç¼ºå¤±æ–‡ä»¶{Style.RESET_ALL}")
            else:
                logger.info(f"{Fore.BLUE}å¼€å§‹ç”Ÿæˆç¼ºå¤±æ–‡ä»¶...{Style.RESET_ALL}")
                
            stats = await GenerateDocAction().run(
                missing_files, 
                self.base_path, 
                structure, 
                self.primary_lang,
                self.dry_run
            )
            self.stats["files_created"] = stats["created"]
        
        return structure
    
    async def synchronize_doc_content(self, structure: dict):
        """åŒæ­¥æ–‡æ¡£å†…å®¹ï¼Œæ›´æ–°ä¸ä¸€è‡´çš„ç¿»è¯‘"""
        logger.info(f"{Fore.CYAN}âœ¨ å¼€å§‹æ£€æŸ¥æ–‡æ¡£å†…å®¹ä¸€è‡´æ€§{Style.RESET_ALL}")
        
        # è·å–æ‰€æœ‰å…±æœ‰çš„æ–‡ä»¶
        common_files = {}
        all_files = set().union(*structure.values()) if structure.values() else set()
        
        # å¯¹æ¯ä¸ªæ–‡ä»¶ï¼ŒæŸ¥æ‰¾å®ƒå­˜åœ¨äºå“ªäº›è¯­è¨€ä¸­
        for file in all_files:
            langs = [lang for lang in structure if file in structure[lang]]
            if len(langs) > 1:  # è‡³å°‘ä¸¤ç§è¯­è¨€éƒ½æœ‰è¿™ä¸ªæ–‡ä»¶
                common_files[file] = langs
        
        logger.info(f"{Fore.CYAN}å…±æœ‰ {len(common_files)} ä¸ªæ–‡ä»¶éœ€è¦æ£€æŸ¥å†…å®¹ä¸€è‡´æ€§{Style.RESET_ALL}")
        
        # æ¯”è¾ƒæ¯ä¸ªå…±æœ‰æ–‡ä»¶åœ¨ä¸åŒè¯­è¨€ç‰ˆæœ¬é—´çš„å†…å®¹å·®å¼‚
        files_to_improve = 0
        files_improved = 0
        
        for file, langs in common_files.items():
            source_path = self.base_path / self.primary_lang / file
            
            # è·³è¿‡ä¸»è¯­è¨€ä¸å­˜åœ¨çš„æ–‡ä»¶
            if not source_path.exists() or self.primary_lang not in langs:
                continue
                
            for target_lang in langs:
                if target_lang == self.primary_lang:
                    continue
                    
                target_path = self.base_path / target_lang / file
                
                if self.verbose:
                    logger.debug(f"æ¯”è¾ƒæ–‡æ¡£: {file} ({self.primary_lang} â†’ {target_lang})")
                
                # æ¯”è¾ƒæ–‡æ¡£å†…å®¹
                comparison_result = await CompareDocumentAction().run(
                    source_path, 
                    target_path, 
                    self.primary_lang, 
                    target_lang
                )
                
                # å¤„ç†æ¯”è¾ƒç»“æœ
                if comparison_result.get("has_differences", False):
                    files_to_improve += 1
                    self.stats["files_to_improve"] += 1
                    
                    # åŒæ­¥æ–‡æ¡£å†…å®¹
                    was_improved = await DocumentSynchronizationAction().run(
                        comparison_result,
                        source_path,
                        target_path,
                        self.primary_lang,
                        target_lang,
                        self.dry_run
                    )
                    
                    if was_improved and not self.dry_run:
                        files_improved += 1
                        self.stats["files_improved"] += 1
                elif self.verbose:
                    logger.debug(f"  âœ“ æ–‡æ¡£å·²åŒæ­¥")
        
        # æ±‡æ€»ç»“æœ
        if files_to_improve > 0:
            if self.dry_run:
                logger.info(f"{Fore.YELLOW}[æ¨¡æ‹Ÿæ¨¡å¼] éœ€è¦æ”¹è¿› {files_to_improve} ä¸ªæ–‡ä»¶{Style.RESET_ALL}")
            else:
                logger.info(f"{Fore.GREEN}å·²æ”¹è¿› {files_improved} ä¸ªæ–‡ä»¶{Style.RESET_ALL}")
        else:
            logger.info(f"{Fore.GREEN}æ‰€æœ‰æ–‡æ¡£å†…å®¹ä¸€è‡´ï¼Œæ— éœ€æ”¹è¿›{Style.RESET_ALL}")
    
    async def run_maintenance(self):
        """è¿è¡Œå®Œæ•´çš„æ–‡æ¡£ç»´æŠ¤æµç¨‹"""
        start_time = datetime.now()
        logger.info(f"{Fore.CYAN}========================================{Style.RESET_ALL}")
        logger.info(f"{Fore.CYAN}ğŸ“š å¼€å§‹æ–‡æ¡£ç»´æŠ¤{Style.RESET_ALL}")
        logger.info(f"{Fore.CYAN}æ–‡æ¡£ç›®å½•: {self.base_path}{Style.RESET_ALL}")
        logger.info(f"{Fore.CYAN}è¯­è¨€: {', '.join(self.lang_dirs)}{Style.RESET_ALL}")
        logger.info(f"{Fore.CYAN}ä¸»è¦è¯­è¨€: {self.primary_lang}{Style.RESET_ALL}")
        if self.dry_run:
            logger.info(f"{Fore.YELLOW}[æ¨¡æ‹Ÿæ¨¡å¼] ä¸ä¼šå®é™…ä¿®æ”¹ä»»ä½•æ–‡ä»¶{Style.RESET_ALL}")
        logger.info(f"{Fore.CYAN}========================================{Style.RESET_ALL}")
        
        try:
            # 1. æ£€æŸ¥å¹¶ç”Ÿæˆç¼ºå¤±æ–‡æ¡£
            structure = await self.check_and_generate_docs()
            
            # 2. åŒæ­¥æ–‡æ¡£å†…å®¹
            await self.synchronize_doc_content(structure)
            
            # 3. æ±‡æ€»ç»“æœ
            end_time = datetime.now()
            duration = (end_time - start_time).total_seconds()
            
            logger.info(f"{Fore.CYAN}========================================{Style.RESET_ALL}")
            logger.info(f"{Fore.CYAN}ğŸ“Š æ–‡æ¡£ç»´æŠ¤å®Œæˆ (è€—æ—¶: {duration:.1f}ç§’){Style.RESET_ALL}")
            logger.info(f"{Fore.CYAN}ç»Ÿè®¡ä¿¡æ¯:{Style.RESET_ALL}")
            logger.info(f"{Fore.BLUE}  - å‘ç°ç¼ºå¤±æ–‡ä»¶: {self.stats['missing_files']} ä¸ª{Style.RESET_ALL}")
            logger.info(f"{Fore.BLUE}  - å‘ç°éœ€æ”¹è¿›æ–‡ä»¶: {self.stats['files_to_improve']} ä¸ª{Style.RESET_ALL}")
            
            if not self.dry_run:
                logger.info(f"{Fore.BLUE}  - åˆ›å»ºæ–°æ–‡ä»¶: {self.stats['files_created']} ä¸ª{Style.RESET_ALL}")
                logger.info(f"{Fore.BLUE}  - æ”¹è¿›æ–‡ä»¶: {self.stats['files_improved']} ä¸ª{Style.RESET_ALL}")
            logger.info(f"{Fore.CYAN}========================================{Style.RESET_ALL}")
            
            return self.stats
        except Exception as e:
            logger.error(f"{Fore.RED}æ–‡æ¡£ç»´æŠ¤è¿‡ç¨‹ä¸­å‡ºé”™: {e}{Style.RESET_ALL}")
            import traceback
            logger.debug(traceback.format_exc())
            return {"error": str(e)}

def setup_argparse():
    """è®¾ç½®å‘½ä»¤è¡Œå‚æ•°è§£æ"""
    parser = argparse.ArgumentParser(
        description="å¤šè¯­è¨€æ–‡æ¡£ç»´æŠ¤å·¥å…· - ç”¨äºæ£€æŸ¥å’ŒåŒæ­¥å¤šè¯­è¨€æ–‡æ¡£",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter
    )
    
    parser.add_argument("-p", "--path", type=str, default="./examples",
                      help="æ–‡æ¡£æ ¹ç›®å½•è·¯å¾„")
                      
    parser.add_argument("-l", "--langs", type=str, default="en,zh",
                      help="è¯­è¨€ç›®å½•åˆ—è¡¨ï¼Œç”¨é€—å·åˆ†éš”")
                      
    parser.add_argument("-m", "--primary", type=str, default="en",
                      help="ä¸»è¦è¯­è¨€ï¼Œç”¨ä½œç¿»è¯‘æº")
                      
    parser.add_argument("-v", "--verbose", action="store_true",
                      help="æ˜¾ç¤ºè¯¦ç»†è¾“å‡ºä¿¡æ¯")
                      
    parser.add_argument("-d", "--dry-run", action="store_true",
                      help="æ¨¡æ‹Ÿæ¨¡å¼ï¼Œä¸å®é™…ä¿®æ”¹æ–‡ä»¶")
                      
    return parser

async def main():
    """ä¸»å‡½æ•°ï¼Œè§£æå‘½ä»¤è¡Œå‚æ•°å¹¶è¿è¡Œæ–‡æ¡£ç»´æŠ¤"""
    parser = setup_argparse()
    args = parser.parse_args()
    
    # è§£æè¯­è¨€åˆ—è¡¨
    lang_dirs = args.langs.split(',')
    
    # åˆ›å»ºç»´æŠ¤å™¨å¹¶è¿è¡Œ
    maintainer = DocMaintainer(
        base_path=args.path,
        lang_dirs=lang_dirs,
        primary_lang=args.primary,
        verbose=args.verbose,
        dry_run=args.dry_run
    )
    
    await maintainer.run_maintenance()

if __name__ == "__main__":
    asyncio.run(main())
